{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import dgl\n",
    "from dgl import function as fn\n",
    "from dgl import DGLGraph\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#set gpu if available\n",
    "if th.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    #device = th.device(\"cuda\")\n",
    "    device = th.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU not available, CPU used\")\n",
    "    device = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_data.csv\").drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['homebuyers_x']).values\n",
    "y = df['homebuyers_x'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.16, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function expects two numpy vectors of equal size, and outputs average square difference\n",
    "def loss_function_1(y_pred, y_labels):\n",
    "    size = y_pred.shape[0]\n",
    "    differences = y_pred - y_labels\n",
    "    differences_square = differences*differences\n",
    "    differences_square_sum = th.sum(differences_square)\n",
    "    \n",
    "    return differences_square_sum/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operation for neigbors\n",
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "    \n",
    "#gcn layer in network\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.pull(g.nodes())\n",
    "        g.apply_nodes(self.apply_mod)\n",
    "        \n",
    "        return g.ndata.pop('h')\n",
    "    \n",
    "#network\n",
    "class DeepGCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(DeepGCN, self).__init__()\n",
    "        self.gcn1 = GCN(in_feats, 256, th.relu)\n",
    "        self.gcn2 = GCN(256, 128, th.relu)\n",
    "        self.gcn3 = GCN(128, 64, th.sigmoid)\n",
    "        self.gcn4 = GCN(64, out_feats, None)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        x = self.gcn3(g, x)\n",
    "        \n",
    "        return self.gcn4(g, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_features = th.FloatTensor(X).to(device) #convert to pytorch data type and add to cpu/gpu\n",
    "ds_labels = th.LongTensor(y).to(device)\n",
    "\n",
    "# add self loop for the sum of festures\n",
    "ds_g = DGLGraph()\n",
    "ds_g.add_nodes(len(ds_features))\n",
    "\n",
    "ds_g.add_edges(ds_g.nodes(), ds_g.nodes())\n",
    "\n",
    "# add row index as column\n",
    "df_graph = pd.read_csv(\"graph.csv\").drop('Unnamed: 0', axis = 1)\n",
    "df_graph = df_graph[(df_graph['0'] < len(df)) & (df_graph['1'] < len(df)) & (df_graph['2'] < len(df))].reset_index()\n",
    "\n",
    "########### Add graph here\n",
    "\n",
    "for idx in range(len(df_graph)):\n",
    "    ds_g.add_edges(df_graph.iloc[idx]['index'], df_graph.iloc[idx][1:].values)\n",
    "\n",
    "########### Add graph here\n",
    "\n",
    "ds_g.ndata['features'] = ds_features\n",
    "ds_g.ndata['t_labels'] = ds_labels\n",
    "\n",
    "m_func = fn.copy_src(src='h', out='m')\n",
    "m_reduce_func = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = th.randperm(len(ds_g.nodes())) #shuffle\n",
    "rand_nodes = ds_g.nodes()[c]\n",
    "\n",
    "\n",
    "# choices = set([random.choice(ds_g.nodes())])\n",
    "# out = set()\n",
    "\n",
    "# while(len(choices) <= int(len(ds_g) * .80)):\n",
    "#     for i in choices:\n",
    "#         out = out.union(ds_g.predecessors(i), ds_g.successors(i))\n",
    "#         if(len(out) + len(choices) > int(len(ds_g) * .80)):\n",
    "#             break\n",
    "\n",
    "#     choices = choices.union(out)\n",
    "#     out = set()\n",
    "\n",
    "# choices = list(choices)\n",
    "\n",
    "train_g = ds_g.subgraph(rand_nodes[:int(len(ds_g) * .80)])#80 percent of all the nodes\n",
    "train_g.copy_from_parent()\n",
    "\n",
    "test_g = ds_g.subgraph(rand_nodes[int(len(ds_g) * .20):])#20 percent of all the nodes\n",
    "test_g.copy_from_parent()\n",
    "test_g.register_message_func(m_func)\n",
    "\n",
    "test_g.register_reduce_func(m_reduce_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant parameters\n",
    "NUMBER_OF_LABELS = th.unique(ds_g.ndata[\"t_labels\"]).size(0)\n",
    "EPOCH = 300\n",
    "\n",
    "model = DeepGCN(ds_features.size()[1], NUMBER_OF_LABELS).to(device)\n",
    "\n",
    "opt = th.optim.Adam(model.parameters(), lr=1e-3)# only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(g, features)\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "hoops = 3\n",
    "\n",
    "losses = np.array([])\n",
    "\n",
    "#train\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(epoch)\n",
    "    \"\"\"\n",
    "    choices = set([random.choice(train_g.nodes()), random.choice(train_g.nodes())])\n",
    "    out = set()\n",
    "    \n",
    "    for neu in range(hoops):\n",
    "        for i in choices:\n",
    "            out = out.union(train_g.predecessors(i), train_g.successors(i))\n",
    "        \n",
    "        choices = choices.union(out)\n",
    "        out = set()\n",
    "    \n",
    "    choices = list(choices)\"\"\"\n",
    "        \n",
    "    c = th.randperm(len(train_g.nodes())) #shuffle\n",
    "    choices = train_g.nodes()[c]\n",
    "    \n",
    "    sub_graph = train_g.subgraph(choices[:int(len(train_g)*.10)])\n",
    "    sub_graph.copy_from_parent()\n",
    "    sub_graph.register_message_func(m_func)\n",
    "    sub_graph.register_reduce_func(m_reduce_func)\n",
    "\n",
    "    feats = sub_graph.ndata['features']\n",
    "    labs = sub_graph.ndata['t_labels'] #true label\n",
    "\n",
    "    out = model(sub_graph, feats)\n",
    "    \n",
    "    out = th.log_softmax(out, 1)\n",
    "    loss = F.nll_loss(out, labs)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    losses = np.append(losses, evaluate(model, test_g, test_g.ndata['features'], test_g.ndata['t_labels']))\n",
    "    \n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(losses)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
